# ================================================================
# BANK‑MARKETING TERM‑DEPOSIT – STREAMLIT PREDICTION APP
# ================================================================
# • Uses artefacts generated by the training script:
#       – bank_marketing_prep_pipeline.joblib   (prep + feature‑sel.)
#       – bank_marketing_knn.pkl                (optimised classifier)
# • Upload campaign data (csv / xlsx) and receive subscription
#   propensity predictions for each record.
# • Optional: persist results to MySQL for downstream BI / reporting
# ----------------------------------------------------------------

import os, pickle, joblib
import pandas as pd
import requests, pickle, joblib
from io import BytesIO
import streamlit as st
import seaborn as sns
import os, pathlib
from PIL import Image
from sqlalchemy import create_engine
from urllib.parse import quote

# ---------------------------------------------------------------
# 1 -- Load artefacts
# ---------------------------------------------------------------

MODEL_URL = "https://github.com/Phani-ISB/ml-ops/raw/main/bank_marketing_knn.pkl"
PIPE_URL  = "https://github.com/Phani-ISB/ml-ops/raw/main/bank_marketing_prep_pipeline.joblib"

# --- download bytes ---
model_bytes = BytesIO(requests.get(MODEL_URL, timeout=30).content)       
pipe_bytes  = BytesIO(requests.get(PIPE_URL,  timeout=30).content)

# --- deserialize ---
model    = pickle.load(model_bytes)                                       
pipeline = joblib.load(pipe_bytes) 

# ---------------------------------------------------------------
# 2 -- Core inference routine
# ---------------------------------------------------------------
def make_predictions(raw_df: pd.DataFrame,
                     db_user: str,
                     db_pw:   str,
                     db_name: str) -> pd.DataFrame:

    # 2‑A  preprocess + feature‑selection
    X_clean = pipeline.transform(raw_df)    # ndarray

    # 2‑B  inference
    preds   = model.predict(X_clean)
    proba   = model.predict_proba(X_clean)[:, 1]  # probability of ‘Subscriber’

    # 2‑C  assemble results
    result = pd.concat([
        pd.Series(preds, name="Predicted_Response"),
        pd.Series(proba, name="Subscription_Probability"),
        raw_df.reset_index(drop=True)
    ], axis=1)

    # 2‑D  optional DB persistence
    if all([db_user, db_pw, db_name]):      # skip if any credential blank
        try:
            eng = create_engine(
                f"mysql+pymysql://{db_user}:{quote(db_pw)}@localhost/{db_name}"
            )
            result.to_sql("bank_campaign_predictions", eng, if_exists="replace",
                          index=False, chunksize=1000)
            st.success("✅ Predictions saved to MySQL – table `bank_campaign_predictions`")
        except Exception as e:
            st.error(f"❌ Could not write to MySQL: {e}")

    return result

# ---------------------------------------------------------------
# 3 -- Streamlit UI
# ---------------------------------------------------------------
def main():

    st.title("Bank (Term‑Deposit) Prediction")
    st.sidebar.header("Upload File")

    # -- File upload widget
    file = st.sidebar.file_uploader("Choose CSV or Excel", type=["csv", "xlsx"])

    # Guard clause: stop execution until a real file arrives
    if file is None:
        st.info("⏳ Awaiting file upload …")
        st.stop()                                    
    # -- Read file based on extension
    ext = pathlib.Path(file.name).suffix.lower()
    if ext == ".csv":
        data = pd.read_csv(file, sep=None, engine="python")  # sep=None 
    elif ext in (".xls", ".xlsx"):
        data = pd.read_excel(file)                  
    else:
        st.error(" Unsupported file type.")
        st.stop()

    # -- Optional MySQL credentials
    st.sidebar.header("Optional – MySQL Persistence")
    user = st.sidebar.text_input("User")
    pw   = st.sidebar.text_input("Password", type="password")
    db   = st.sidebar.text_input("Database")

    if st.button("Predict"):
        with st.spinner("Running inference …"):
            results = make_predictions(data, user, pw, db)
        
        # Quick counts
       
        counts = results["Predicted_Response"].value_counts().to_dict()
        st.info(f"Non‑subscriber : {counts.get('Non-subscriber',0)}  |  "
                f"Subscriber : {counts.get('Subscriber',0)}")
        # -- Pretty display
        
        cmap = sns.light_palette("green", as_cmap=True)
        st.subheader("Results")
        st.table(
            results.style
                   .format({"Subscription_Probability": "{:.2%}"})
                   .background_gradient(cmap=cmap,
                                        subset=["Subscription_Probability"])
        )

        

# -----------------------------------------------------------------
if __name__ == "__main__":
    main()
