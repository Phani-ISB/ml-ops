# ================================================================
# BANK‑MARKETING TERM‑DEPOSIT – STREAMLIT PREDICTION APP
# ================================================================
# • Uses artefacts generated by the training script:
#       – bank_marketing_prep_pipeline.joblib   (prep + feature‑sel.)
#       – bank_marketing_knn.pkl                (optimised classifier)
# • Upload campaign data (csv / xlsx) and receive subscription
#   propensity predictions for each record.
# • Optional: persist results to MySQL for downstream BI / reporting
# ----------------------------------------------------------------

import os, pickle, joblib
import pandas as pd
import streamlit as st
import seaborn as sns
from PIL import Image
from sqlalchemy import create_engine
from urllib.parse import quote

# ---------------------------------------------------------------
# 1 -- Load artefacts
# ---------------------------------------------------------------
MODEL_PATH = "bank_marketing_knn.pkl"
PIPE_PATH  = "bank_marketing_prep_pipeline.joblib"

model    = pickle.load(open(MODEL_PATH, "rb"))
pipeline = joblib.load(PIPE_PATH)           # preprocessing + FS

# ---------------------------------------------------------------
# 2 -- Core inference routine
# ---------------------------------------------------------------
def make_predictions(raw_df: pd.DataFrame,
                     db_user: str,
                     db_pw:   str,
                     db_name: str) -> pd.DataFrame:

    # 2‑A  preprocess + feature‑selection
    X_clean = pipeline.transform(raw_df)    # ndarray

    # 2‑B  inference
    preds   = model.predict(X_clean)
    proba   = model.predict_proba(X_clean)[:, 1]  # probability of ‘Subscriber’

    # 2‑C  assemble results
    result = pd.concat([
        pd.Series(preds, name="Predicted_Response"),
        pd.Series(proba, name="Subscription_Probability"),
        raw_df.reset_index(drop=True)
    ], axis=1)

    # 2‑D  optional DB persistence
    if all([db_user, db_pw, db_name]):      # skip if any credential blank
        try:
            eng = create_engine(
                f"mysql+pymysql://{db_user}:{quote(db_pw)}@localhost/{db_name}"
            )
            result.to_sql("bank_campaign_predictions", eng, if_exists="replace",
                          index=False, chunksize=1000)
            st.success("✅ Predictions saved to MySQL – table `bank_campaign_predictions`")
        except Exception as e:
            st.error(f"❌ Could not write to MySQL: {e}")

    return result

# ---------------------------------------------------------------
# 3 -- Streamlit UI
# ---------------------------------------------------------------
def main():
    # -- sidebar branding (logo optional)
    if os.path.exists("AiSPRY logo.jpg"):
        st.sidebar.image(Image.open("AiSPRY logo.jpg"), use_column_width=True)

    st.title("Bank‑Marketing Term‑Deposit Prediction")
    st.sidebar.header("Upload Campaign File")

    # -- file upload
    file = st.sidebar.file_uploader("Choose CSV or Excel", type=["csv", "xlsx"])
    if not file:
        st.info("⏳ Awaiting file upload …")
        st.stop()

    # -- read file
    try:
        data = pd.read_csv(file, sep=None)   # sep=None lets pandas sniff delimiter
    except Exception:
        data = pd.read_excel(file)

    # -- MySQL creds (optional)
    st.sidebar.header("Optional – MySQL Persistence")
    user = st.sidebar.text_input("User")
    pw   = st.sidebar.text_input("Password", type="password")
    db   = st.sidebar.text_input("Database")

    if st.button("Predict"):
        with st.spinner("Running inference …"):
            results = make_predictions(data, user, pw, db)

        # -- pretty display
        cmap = sns.light_palette("green", as_cmap=True)
        st.subheader("Results")
        st.table(
            results.style
                   .format({"Subscription_Probability": "{:.2%}"})
                   .background_gradient(cmap=cmap, subset=["Subscription_Probability"])
        )

        # quick counts
        counts = results["Predicted_Response"].value_counts().to_dict()
        st.info(f"Non‑subscriber: {counts.get('Non-subscriber',0)} | Subscriber: {counts.get('Subscriber',0)}")

# ---------------------------------------------------------------
if __name__ == "__main__":
    main()
